{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1914fe2-e9d1-44ee-885f-7d1cf792dee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from datasets import load_dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3cea35-4b26-4036-b109-fb407477c0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before executing this code download the court order files with \n",
    "#\n",
    "#    https://github.com/niklaswais/gesp \n",
    "#\n",
    "# and specify the download directory below in gesp_dir.\n",
    "#--------------------------------------------------------------------\n",
    "\n",
    "gesp_dir = Path('D:\\Projects\\gesp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046d64b1-6e4e-40af-9758-5610e0ebda11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all court order filenames and associated federated state names\n",
    "#--------------------------------------------------------------------\n",
    "\n",
    "state_dirs =  [f for f in gesp_dir.iterdir() if f.is_dir()]\n",
    "\n",
    "for f in state_dirs:\n",
    "    print(f)\n",
    "\n",
    "files = [f for f in gesp_dir.iterdir() if f.is_file()]\n",
    "\n",
    "f = state_dirs[0]\n",
    "\n",
    "order = [];     # court order file name\n",
    "order_st = [];  # court order federated state name\n",
    "\n",
    "states = {'bb':'Brandenburg',\n",
    "          'be':'Berlin',\n",
    "          'bw':'Baden-Württemberg',\n",
    "          'by':'Bayern',\n",
    "          'he':'Hessen',\n",
    "          'hh':'Hamburg',\n",
    "          'mv':'Mecklenburg-Vorpommern',\n",
    "          'ni':'Niedersachsen',\n",
    "          'nw':'Nordrhein-Westfalen',\n",
    "          'rp':'Rheinland-Pfalz',\n",
    "          'sh':'Schleswig-Holstein',\n",
    "          'sl':'Saarland',\n",
    "          'st':'Sachsen-Anhalt',\n",
    "          'th':'Thüringen'}\n",
    "\n",
    "for path, subdirs, files in os.walk(gesp_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(\".html\"):\n",
    "            order.append(os.path.join(path, file))\n",
    "            order_st.append(path[-2:])\n",
    "\n",
    "\n",
    "print('%g court orders found.' % (len(order)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ae1483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create text phrases to be detected in the verdicts\n",
    "#--------------------------------------------------------------------\n",
    "\n",
    "tmp_cl0  = ['Kosten haben die PLU1 zu tragen',\n",
    "            'Kosten hat der MAS1 zu tragen',\n",
    "            'Kosten hat die FEM1 zu tragen',\n",
    "            'PLU1 haben die Kosten zu tragen',\n",
    "            'MAS1 hat die Kosten zu tragen',\n",
    "            'FEM1 hat die Kosten zu tragen',\n",
    "            'FEM1 trägt die Kosten',\n",
    "            'MAS1 trägt die Kosten',\n",
    "            'PLU1 tragen die Kosten',\n",
    "            'Kosten trägt der MAS1',\n",
    "            'Kosten trägt die FEM1',\n",
    "            'Kosten tragen die PLU1',\n",
    "            'Kosten werden den PLU2 auferlegt',\n",
    "            'Kosten werden der FEM2 auferlegt',\n",
    "            'Kosten werden dem MAS2 auferlegt',      \n",
    "            'PLU2 werden die Kosten auferlegt',\n",
    "            'FEM2 werden die Kosten auferlegt',\n",
    "            'MAS2 werden die Kosten auferlegt']\n",
    "\n",
    "dict0 = {'MAS1': ['Kläger','Antragsteller','Beschwerdeführer'],\n",
    "         'FEM1': ['Klägerin','Antragstellerin','klagende Partei','Beschwerdeführerin'],\n",
    "         'PLU1': ['Kläger','Antragsteller','Beschwerdeführer'],\n",
    "         'MAS2': ['Kläger','Antragsteller','Beschwerdeführer'],\n",
    "         'FEM2': ['Klägerin','Antragstellerin','klagenden Partei','Beschwerdeführerin'],\n",
    "         'PLU2': ['Klägern','Antragstellern','Beschwerdeführern']\n",
    "        }\n",
    "\n",
    "text_cl0 = ['abgewiesen',\n",
    "            'zurückgewiesen']\n",
    "\n",
    "for t in tmp_cl0:\n",
    "    for j,(k,v) in enumerate(dict0.items()): \n",
    "        if t.find(k)>-1:\n",
    "            for i,marker in enumerate(v):\n",
    "                text_cl0 += [t.replace(k,marker)] \n",
    "\n",
    "\n",
    "tmp_cl1  = ['Kosten haben die PLU1 zu tragen',\n",
    "            'Kosten hat die FEM1 zu tragen',\n",
    "            'Kosten hat der MAS1 zu tragen',\n",
    "            'PLU1 haben die Kosten zu tragen',\n",
    "            'FEM1 hat die Kosten zu tragen',\n",
    "            'MAS1 hat die Kosten zu tragen',\n",
    "            'PLU1 tragen die Kosten',\n",
    "            'FEM1 trägt die Kosten',\n",
    "            'MAS1 trägt die Kosten',\n",
    "            'Kosten tragen die PLU1',\n",
    "            'Kosten trägt die FEM1',\n",
    "            'Kosten trägt der MAS1',\n",
    "            'Kosten werden den PLU2 auferlegt',\n",
    "            'Kosten werden der FEM2 auferlegt',\n",
    "            'Kosten werden dem MAS2 auferlegt',      \n",
    "            'PLU2 werden die Kosten auferlegt',\n",
    "            'FEM2 werden die Kosten auferlegt',\n",
    "            'MAS2 werden die Kosten auferlegt']\n",
    "\n",
    "dict1 = {'MAS1': ['Angeklagte','Beklagte','Antragsgegner'],\n",
    "         'FEM1': ['Angeklagte','Beklagte','Antragsgegnerin','beklagte Partei'] ,\n",
    "         'PLU1': ['Angeklagten','Beklagten','Antragsgegner'],\n",
    "         'MAS2': ['Angeklagten','Beklagten','Antragsgegner'] ,\n",
    "         'FEM2': ['Angeklagten','Beklagten','Antragsgegnerin','beklagten Partei'] ,\n",
    "         'PLU2': ['Angeklagten','Beklagten','Antragsgegnern'],\n",
    "        }\n",
    "\n",
    "text_cl1 = ['werden verurteilt',\n",
    "            'wird verurteilt']\n",
    "\n",
    "for t in tmp_cl1:\n",
    "    for j,(k,v) in enumerate(dict1.items()): \n",
    "        if t.find(k)>-1:\n",
    "            for i,marker in enumerate(v):\n",
    "                text_cl1 += [t.replace(k,marker)] \n",
    "\n",
    "\n",
    "text = text_cl0[:]\n",
    "for t in text:\n",
    "    if t.find('Kosten')>-1:\n",
    "        text_cl0 += [t.replace('Kosten','Gesamtkosten')] \n",
    "           \n",
    "            \n",
    "text = text_cl1[:]\n",
    "for t in text:\n",
    "    if t.find('Kosten')>-1:\n",
    "        text_cl1 += [t.replace('Kosten','Gesamtkosten')] \n",
    "\n",
    "to_remove = ['außergerichtlichen','gerichtlichen','und','notwendigen','gesamten','weiteren',\n",
    "             'des Berufungsverfahrens','des Verfahrens','der Berufung','des Rechtsstreits', \n",
    "             'als Gesamtschuldner','als Gesamtschuldnerin','als Gesamtschuldnerinnen', \n",
    "             'seines Rechtsmittels','ihres Rechtsmittels','des Rechtsmittels']   \n",
    "\n",
    "# all strings to lower case\n",
    "\n",
    "for i,t in enumerate(to_remove):\n",
    "    to_remove[i] = t.lower()    \n",
    "        \n",
    "for i,t in enumerate(text_cl0):\n",
    "    text_cl0[i] = t.lower()    \n",
    "    \n",
    "for i,t in enumerate(text_cl1):\n",
    "    text_cl1[i] = t.lower()     \n",
    "\n",
    "text_cl0 = np.unique(text_cl0).tolist()\n",
    "text_cl1 = np.unique(text_cl1).tolist()\n",
    "\n",
    "# logical indices selecting certain elements of text_cl0 and text_cl1 \n",
    "# ('dismissed','convicted','costs to plaintiff','costs to defendant')\n",
    "id0a = [t in ['zurückgewiesen','abgewiesen'] for t in text_cl0]\n",
    "id0b = [t not in ['zurückgewiesen','abgewiesen'] for t in text_cl0]\n",
    "id1a = [t in ['werden verurteilt','wird verurteilt'] for t in text_cl1]\n",
    "id1b = [t not in ['werden verurteilt','wird verurteilt'] for t in text_cl1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f87dee-aee8-4703-9f80-550aeaeb09ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data dictionary from html files\n",
    "#--------------------------------------------------------------------\n",
    "\n",
    "# function converting html to text \n",
    "def get_text(i):\n",
    "    with open(order[i],'r',encoding='utf-8') as f:\n",
    "        html = f.read() \n",
    "        text= BeautifulSoup(html).get_text(\"\\n\",strip=True)   # for readability keep newline\n",
    "    \n",
    "    return text\n",
    "\n",
    "# data dictionary\n",
    "dd =  {'state': [],\n",
    "       'court': [],\n",
    "       'date': [],\n",
    "       'decision': [],\n",
    "       'offense': [],\n",
    "       'dismissed': [],          # word appearance 'zurückgewiesen','abgewiesen'\n",
    "       'convicted': [],          # word appearance 'werden verurteilt','wird verurteilt'\n",
    "       'costs to plaintiff': [], # 'Kosten an klagende Partei'\n",
    "       'costs to defendant': [], # 'Kosten an beklagte Partein'\n",
    "      }\n",
    "\n",
    "markers = ['\\nGericht:','\\nEntscheidungsdatum:','\\nTenor\\n','\\nTatbestand\\n','\\nGründe\\n','\\nEntscheidungsgründe\\n','\\nGründe:','\\nEntscheidungsgründe:','\\nPermalink']\n",
    "markersL = markers[:]\n",
    "for i,t in enumerate(markers):\n",
    "    markersL[i] = t.lower()  \n",
    "\n",
    "k0 = markers.index('\\nTenor\\n')\n",
    "k1 = markers.index('\\nTatbestand\\n')\n",
    "k2 = markers.index('\\nGericht:')\n",
    "k3 = markers.index('\\nEntscheidungsdatum:')\n",
    "    \n",
    "m = np.zeros([len(order),len(markers)])\n",
    "m0 = np.zeros([len(order),len(text_cl0)])\n",
    "m1 = np.zeros([len(order),len(text_cl1)])\n",
    "\n",
    "for i in tqdm(range(len(order)), desc =\"Read court orders\"): \n",
    "\n",
    "    # load court order\n",
    "    Text = get_text(i)\n",
    "    text = Text.lower()\n",
    "    \n",
    "    # find location of markers within the court order\n",
    "    for j, marker in enumerate(markers):\n",
    "        m[i,j] = Text.find(marker)\n",
    "\n",
    "\n",
    "    #  dismiss markers with colon (these don't occur anyway)\n",
    "    if text.find('Tenor:')>-1:\n",
    "        print('Skip order %g.' % (i))\n",
    "        continue\n",
    "        \n",
    "    if text.find('Tatbestand:')>-1:\n",
    "        print('Skip order %g.' % (i))\n",
    "        continue\n",
    "\n",
    "    n0 = int(m[i,k0])  # location of 'tenor'\n",
    "    n1 = int(m[i,k1])  # location of 'Tatbestand'\n",
    "    n2 = int(m[i,k2])  # location of 'Gericht:'\n",
    "    n3 = int(m[i,k3])  # location of 'Entscheidungsdatum:'\n",
    "\n",
    "    # check if 'tenor'and 'Tatbestand' are available\n",
    "    if (n0>0)&(n1>0):\n",
    "        # ni = int( np.min( m[i, m[i,:] > n0 ] ))   # Text from 'Tenor' to any next marker\n",
    "        ni = int( np.min( np.concatenate( ([len(Text)],m[i, m[i,:] > n0 ]) )) ) # Text from 'Tenor' to any next marker\n",
    "        nj = int( np.min( np.concatenate( ([len(Text)],m[i, m[i,:] > n1 ]) )) ) # Text from 'Tatbestand' to any next marker or end\n",
    "\n",
    "        if (ni <= n0)|(nj <= n1):\n",
    "            print('Check problem with order %g.' % (i))\n",
    "            print(order[i])\n",
    "        if (n0>n1):\n",
    "            print('Check flipped Tenor and Tatbestand in order %g.' % (i))\n",
    "            print(order[i])\n",
    "        \n",
    "        tenor = text[n0:ni]    \n",
    "            \n",
    "        # remove distracting fill words \n",
    "        for j, marker in enumerate(to_remove):\n",
    "            tenor = tenor.replace(marker+' ','')\n",
    "         \n",
    "        for j, marker in enumerate(text_cl0):\n",
    "            m0[i,j] = tenor.find(marker)\n",
    "        \n",
    "        for j, marker in enumerate(text_cl1):\n",
    "            m1[i,j] = tenor.find(marker)\n",
    "\n",
    "        # add data to dictionary\n",
    "        date = Text[n3+21:n3+31] if n3>-1 else ''\n",
    "        court = Text[n2+10:n3] if (n2>-1)&(n3>-1) else ''\n",
    "        Tenor = Text[n0+7:ni]\n",
    "        Tatbestand = Text[n1+12:nj]\n",
    "            \n",
    "        b0a = int( (m0[i,id0a]>-1).any() )\n",
    "        b0b = int( (m0[i,id0b]>-1).any() )\n",
    "        b1a = int( (m1[i,id1a]>-1).any() )\n",
    "        b1b = int( (m1[i,id1b]>-1).any() )\n",
    "\n",
    "        if not Tenor:\n",
    "            print('Check empty Tenor in order %g.' % (i))\n",
    "            continue\n",
    "            \n",
    "        if not Tatbestand:\n",
    "            print('Check empty Tatbestand in order %g.' % (i))\n",
    "            continue\n",
    "            \n",
    "        dd['state'].append(states[order_st[i]])\n",
    "        dd['court'].append(court)\n",
    "        dd['date'].append(date)\n",
    "        dd['decision'].append(Tenor)               # Tenor (not in lower case)\n",
    "        dd['offense'].append(Tatbestand)           # Tatbestand (not in lower case)\n",
    "        dd['dismissed'].append(b0a)                # word appearance 'zurückgewiesen','abgewiesen'\n",
    "        dd['convicted'].append(b1a)                # word appearance 'werden verurteilt','wird verurteilt'\n",
    "        dd['costs to plaintiff'].append(b0b)       # 'Kosten an klagende Partei'\n",
    "        dd['costs to defendant'].append(b1b)       # 'Kosten an beklagte Partein'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5bc9f7-e035-4d4a-b6d5-fb273967aca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataset to json\n",
    "savefilename1 = 'data_court_decisions.json'\n",
    "df = pd.DataFrame(dd)\n",
    "df.to_json(savefilename1,orient='records')\n",
    "print(savefilename1)\n",
    "\n",
    "# save dataset to jsonl\n",
    "json_lines_dataset = load_dataset('json',data_files=savefilename1) # see if data is in the right json format to be loaded\n",
    "savefilename2 = 'german_court_decisions'\n",
    "json_lines_dataset.save_to_disk(savefilename2)\n",
    "print(savefilename2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
